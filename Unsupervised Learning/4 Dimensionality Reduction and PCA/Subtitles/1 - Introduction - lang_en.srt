1
00:00:04,400 --> 00:00:09,855
Welcome to this lesson on Principal Component Analysis or PCA.

2
00:00:09,855 --> 00:00:11,880
The techniques you've seen so far in

3
00:00:11,880 --> 00:00:15,085
this lesson had been about clustering your data together.

4
00:00:15,085 --> 00:00:20,469
This begins our journey on unsupervised learning techniques aimed at transforming data,

5
00:00:20,469 --> 00:00:22,279
rather than clustering it.

6
00:00:22,280 --> 00:00:25,410
The main use of transformation techniques like

7
00:00:25,410 --> 00:00:30,118
PCA is that it allows you to retain the informative parts of your data,

8
00:00:30,118 --> 00:00:31,589
but with less of it.

9
00:00:31,589 --> 00:00:33,280
Let's say you ask me,

10
00:00:33,280 --> 00:00:35,539
"Hey, what do you have for breakfast today?"

11
00:00:35,539 --> 00:00:37,570
I could say, "So,

12
00:00:37,570 --> 00:00:38,579
I was running late,

13
00:00:38,579 --> 00:00:40,314
I was going to grab a Nutrigain Bar,

14
00:00:40,314 --> 00:00:41,710
but then I noticed I was all out.

15
00:00:41,710 --> 00:00:43,825
So, I stopped by the coffee shop,

16
00:00:43,825 --> 00:00:45,795
and I grabbed a coffee,

17
00:00:45,795 --> 00:00:46,950
and then I was a little hungry,

18
00:00:46,950 --> 00:00:48,900
so I also grabbed a pastry."

19
00:00:48,899 --> 00:00:52,289
Alternatively, I could condense the answer to,

20
00:00:52,289 --> 00:00:54,344
I had a coffee and a pastry.

21
00:00:54,344 --> 00:00:59,354
The information needed to answer the question is available in both.

22
00:00:59,354 --> 00:01:03,774
But the second, pulls the necessary information from the first.

23
00:01:03,774 --> 00:01:06,995
This is how Principal Component Analysis works.

24
00:01:06,995 --> 00:01:11,939
PCA is the first of the techniques we will look at that uses what it knows about

25
00:01:11,939 --> 00:01:17,209
your data set to reduce it to only the parts that contain the most information.

