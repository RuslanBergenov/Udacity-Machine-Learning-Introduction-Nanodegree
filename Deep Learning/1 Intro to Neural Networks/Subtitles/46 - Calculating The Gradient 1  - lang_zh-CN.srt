1
00:00:00,000 --> 00:00:02,653
和之前一样

2
00:00:02,653 --> 00:00:06,278
我们在神经网络图中标记权重 以便更好地分类点

3
00:00:06,280 --> 00:00:07,679
但是这一次 我们将使用严谨的表达式

4
00:00:07,679 --> 00:00:10,349
所以请保持注意集中 一大堆数学知识就要来了

5
00:00:10,349 --> 00:00:13,785
在左侧是单个感知器 带有输入向量

6
00:00:13,785 --> 00:00:18,879
权重 偏差和 s 函数 它们都在这个节点内

7
00:00:18,879 --> 00:00:22,004
右侧是预测所使用的公式

8
00:00:22,004 --> 00:00:27,050
输入先经过一个线性方程 再经过 s 函数

9
00:00:27,050 --> 00:00:30,820
下面是误差公式

10
00:00:30,820 --> 00:00:34,520
它是所有点的平均结果

11
00:00:34,520 --> 00:00:38,799
蓝色项和红色项分别代表蓝点和红点

12
00:00:38,798 --> 00:00:41,185
为了从误差之巅上下来

13
00:00:41,185 --> 00:00:43,269
我们需要计算梯度

14
00:00:43,268 --> 00:00:48,608
梯度是误差函数关于权重（从 w1 到 wn）和偏差的偏导数

15
00:00:48,609 --> 00:00:55,630
所形成的向量

16
00:00:55,630 --> 00:00:58,420
它们所对应的是这些边

17
00:00:58,420 --> 00:01:01,399
在多层感知器中该如何进行反向传播？

18
00:01:01,399 --> 00:01:05,405
这种情况稍微复杂些 但本质上几乎一样

19
00:01:05,405 --> 00:01:07,233
这是我们的预测结果

20
00:01:07,233 --> 00:01:13,503
其实就是一些复合函数 包括矩阵乘法和 s 函数

21
00:01:13,504 --> 00:01:16,055
误差函数几乎保持不变

22
00:01:16,055 --> 00:01:19,234
只是 ŷ 稍微复杂些

23
00:01:19,233 --> 00:01:21,649
梯度几乎一样

24
00:01:21,650 --> 00:01:23,799
只是表达式长了很多

25
00:01:23,799 --> 00:01:25,909
它是一个庞大的向量

26
00:01:25,909 --> 00:01:29,984
每一项分别是误差函数关于每个权重的偏导数

27
00:01:29,983 --> 00:01:32,582
这些项对应所有的边

28
00:01:32,584 --> 00:01:34,489
如果要写的更严谨一些

29
00:01:34,489 --> 00:01:39,500
我们知道预测结果是 s 函数和矩阵乘法的复合

30
00:01:39,500 --> 00:01:42,000
这些是矩阵

31
00:01:42,000 --> 00:01:45,765
梯度由所有这些偏导数组成

32
00:01:45,765 --> 00:01:47,579
这里看起来像个矩阵

33
00:01:47,578 --> 00:01:49,198
但实际上是个很长的向量

34
00:01:49,200 --> 00:01:51,730
梯度下降法将进行如下步骤

35
00:01:51,730 --> 00:01:53,430
我们拿出每个权重 wij(k)

36
00:01:53,430 --> 00:01:59,206
我们对其进行更新

37
00:01:59,206 --> 00:02:06,125
加上一个小数字（也就是学习速率）乘以 E 相对于该权重的偏导数

38
00:02:06,125 --> 00:02:07,819
这是梯度下降的步骤

39
00:02:07,819 --> 00:02:14,270
这样将得到更新后的权重 wij’(k)

40
00:02:14,270 --> 00:02:16,919
于是就得到了一个全新的模型

41
00:02:16,919 --> 00:02:20,270
它包含了新的权重 可以对点进行更准确的分类

