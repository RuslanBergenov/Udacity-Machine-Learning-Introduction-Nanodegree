1
00:00:00,000 --> 00:00:03,990
我们来对比感知器算法和梯度下降算法

2
00:00:03,990 --> 00:00:05,845
在梯度下降算法中

3
00:00:05,845 --> 00:00:09,535
我们得到权重 从 Wi 改为

4
00:00:09,535 --> 00:00:13,915
Wi + α (y -y-hat) Xi

5
00:00:13,915 --> 00:00:15,325
在感知器算法中

6
00:00:15,325 --> 00:00:17,253
并不是每个点改变权重

7
00:00:17,253 --> 00:00:18,960
只有分类错误的点

8
00:00:18,960 --> 00:00:21,385
如果 x 被误分类

9
00:00:21,385 --> 00:00:27,525
如果点的标签为正 我们会把 Xi 加上 Wi 来改变权重

10
00:00:27,525 --> 00:00:29,785
如果为负 就要减去

11
00:00:29,785 --> 00:00:32,327
现在问题是这两个是相同的吗？

12
00:00:32,327 --> 00:00:34,920
我们回忆下在感知器算法中

13
00:00:34,920 --> 00:00:37,350
标签是 0 和 1

14
00:00:37,350 --> 00:00:40,320
预测 Y-hat 也是 0 和 1

15
00:00:40,320 --> 00:00:43,060
如果点是正确分类的

16
00:00:43,060 --> 00:00:48,440
那么 y- y-hat 为 0 因为 y 等于 y-hat

17
00:00:48,440 --> 00:00:50,205
如果点为蓝色

18
00:00:50,205 --> 00:00:52,095
那么 y 等于 1

19
00:00:52,095 --> 00:00:53,220
如果是错误分类的

20
00:00:53,220 --> 00:00:55,950
那么预测为 y-hat = 0

21
00:00:55,950 --> 00:00:59,265
y-hat - y 等于 -1

22
00:00:59,265 --> 00:01:01,050
类似地 点标记为红色

23
00:01:01,050 --> 00:01:04,105
那么 y = 0 而且 y-hat = 1

24
00:01:04,105 --> 00:01:06,180
那么 y-hat - y 等于 1

25
00:01:06,180 --> 00:01:08,300
这可能不会立即很清晰

26
00:01:08,300 --> 00:01:10,035
不过如果你长时间注视着屏幕

27
00:01:10,035 --> 00:01:13,620
你会发现右侧和左侧完全相同

28
00:01:13,620 --> 00:01:15,175
唯一的不同在于左侧

29
00:01:15,175 --> 00:01:17,776
Y-hat 是 0 到 1 之间的任何数字

30
00:01:17,776 --> 00:01:19,650
而在右侧

31
00:01:19,650 --> 00:01:23,305
Y-hat 只能是数字 0 或 1

32
00:01:23,305 --> 00:01:25,175
非常有趣 对不对？

33
00:01:25,175 --> 00:01:28,055
我们来更加认真地学习梯度下降

34
00:01:28,055 --> 00:01:31,680
在感知器算法和梯度下降算法中

35
00:01:31,680 --> 00:01:36,570
这个被误分类的点让一条线段更加靠近

36
00:01:36,570 --> 00:01:40,770
因为最终它想要这条线段越过它 这样可以处于正确的一侧

37
00:01:40,770 --> 00:01:43,734
如果点被正确分类 会发生什么呢？

38
00:01:43,734 --> 00:01:47,315
感知器算法表示什么都不做

39
00:01:47,315 --> 00:01:49,575
在梯度下降算法中

40
00:01:49,575 --> 00:01:51,195
你可以改变权重

41
00:01:51,195 --> 00:01:52,830
可是如何做到呢？

42
00:01:52,830 --> 00:01:54,480
如果我们仔细观察

43
00:01:54,480 --> 00:01:56,640
这个点要求这条直线

44
00:01:56,640 --> 00:01:58,875
移动到更远的地方

45
00:01:58,875 --> 00:02:01,120
这样说得通 对不对？

46
00:02:01,120 --> 00:02:03,180
因为如果正确分类

47
00:02:03,180 --> 00:02:05,895
也就是说 蓝点位于蓝色区域

48
00:02:05,895 --> 00:02:08,385
可能更容易进入蓝色区域

49
00:02:08,385 --> 00:02:10,740
预测值更接近 1

50
00:02:10,740 --> 00:02:13,060
误差更小

51
00:02:13,060 --> 00:02:16,320
同样 红点位于红色区域

52
00:02:16,320 --> 00:02:19,590
这个点要求这条直线远离是说得通的

53
00:02:19,590 --> 00:02:22,925
这就是梯度下降算法的用途

54
00:02:22,925 --> 00:02:26,540
误分类的点要求直线更加靠近

55
00:02:26,540 --> 00:02:30,315
而正确分类的点要求直线远离

56
00:02:30,315 --> 00:02:33,240
这条直线结合所有点的要求 然后按照这种方式移动

57
00:02:33,240 --> 00:02:37,000
最后达到相当良好的解决方案

