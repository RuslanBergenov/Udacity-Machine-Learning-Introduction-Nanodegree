{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural networks with PyTorch\n",
    "\n",
    "Deep learning networks tend to be massive with dozens or hundreds of layers, that's where the term \"deep\" comes from. You can build one of these deep networks using only weight matrices as we did in the previous notebook, but in general it's very cumbersome and difficult to implement. PyTorch has a nice module `nn` that provides a nice way to efficiently build large neural networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary packages\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "import helper\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Now we're going to build a larger network that can solve a (formerly) difficult problem, identifying text in an image. Here we'll use the MNIST dataset which consists of greyscale handwritten digits. Each image is 28x28 pixels, you can see a sample below\n",
    "\n",
    "<img src='assets/mnist.png'>\n",
    "\n",
    "Our goal is to build a neural network that can take one of these images and predict the digit in the image.\n",
    "\n",
    "First up, we need to get our dataset. This is provided through the `torchvision` package. The code below will download the MNIST dataset, then create training and test datasets for us. Don't worry too much about the details here, you'll learn more about this later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Run this cell\n",
    "\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "# Define a transform to normalize the data\n",
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                              transforms.Normalize((0.5,), (0.5,)),\n",
    "                              ])\n",
    "# Download and load the training data\n",
    "trainset = datasets.MNIST('~/.pytorch/MNIST_data/', download=True, train=True, transform=transform)\n",
    "torch.manual_seed(7) \n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have the training data loaded into `trainloader` and we make that an iterator with `iter(trainloader)`. Later, we'll use this to loop through the dataset for training, like\n",
    "\n",
    "```python\n",
    "for image, label in trainloader:\n",
    "    ## do things with images and labels\n",
    "```\n",
    "\n",
    "You'll notice I created the `trainloader` with a batch size of 64, and `shuffle=True`. The batch size is the number of images we get in one iteration from the data loader and pass through our network, often called a *batch*. And `shuffle=True` tells it to shuffle the dataset every time we start going through the data loader again. But here I'm just grabbing the first batch so we can check out the data. We can see below that `images` is just a tensor with size `(64, 1, 28, 28)`. So, 64 images per batch, 1 color channel, and 28x28 images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()\n",
    "print(type(images))\n",
    "print(images.shape)\n",
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is what one of the images looks like. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 248,
       "width": 251
      },
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(images[1].numpy().squeeze(), cmap='Greys_r');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's try to build a simple network for this dataset using weight matrices and matrix multiplications. Then, we'll see how to do it using PyTorch's `nn` module which provides a much more convenient and powerful method for defining network architectures.\n",
    "\n",
    "The networks you've seen so far are called *fully-connected* or *dense* networks. Each unit in one layer is connected to each unit in the next layer. In fully-connected networks, the input to each layer must be a one-dimensional vector (which can be stacked into a 2D tensor as a batch of multiple examples). However, our images are 28x28 2D tensors, so we need to convert them into 1D vectors. Thinking about sizes, we need to convert the batch of images with shape `(64, 1, 28, 28)` to a have a shape of `(64, 784)`, 784 is 28 times 28. This is typically called *flattening*, we flattened the 2D images into 1D vectors.\n",
    "\n",
    "Previously you built a network with one output unit. Here we need 10 output units, one for each digit. We want our network to predict the digit shown in an image, so what we'll do is calculate probabilities that the image is of any one digit or class. This ends up being a discrete probability distribution over the classes (digits) that tells us the most likely class for the image. That means we need 10 output units for the 10 classes (digits). We'll see how to convert the network output into a probability distribution next.\n",
    "\n",
    "> **Exercise:** Flatten the batch of images `images`. Then build a multi-layer network with 784 input units, 256 hidden units, and 10 output units using random tensors for the weights and biases. For now, use a sigmoid activation for the hidden layer. Leave the output layer without an activation, we'll add one that gives us a probability distribution next."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "torch.Size([64, 784])\n"
     ]
    }
   ],
   "source": [
    "inputs = images.view(images.shape[0], -1)\n",
    "print(type(inputs))\n",
    "print(inputs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "out_shape: torch.Size([64, 10])\n",
      "out: tensor([[-1.4023e+01, -1.1042e+01, -5.5446e-02, -8.5413e+00,  1.4610e+01,\n",
      "          1.3467e+01, -1.4717e+01, -3.1554e+00, -1.0507e+01, -4.3840e+00],\n",
      "        [-1.3602e+01, -1.2563e+01,  7.8807e-01, -3.0656e+00,  9.4789e+00,\n",
      "          4.6989e+00, -4.1930e-01,  3.2248e+00, -1.0575e+01,  1.7720e+00],\n",
      "        [-1.0112e+01, -1.2590e+01, -3.9102e+00, -1.2615e+01,  4.7334e+00,\n",
      "          3.7853e+00, -9.9623e+00,  5.8477e+00, -2.2561e+01,  3.4284e+00],\n",
      "        [-1.7231e+01, -1.1577e+01,  6.3963e-01, -1.3755e+01,  8.4990e+00,\n",
      "          7.9737e+00,  4.1870e-01,  6.5722e+00, -1.2720e+01, -1.0073e+01],\n",
      "        [-1.5905e+01, -8.9751e+00, -8.9112e-01, -1.5226e+01,  1.2166e+01,\n",
      "          7.0617e+00,  1.1042e+00,  1.3038e+01, -1.1376e+01, -1.1886e+01],\n",
      "        [-9.0754e+00, -3.1877e+00, -1.5929e+00, -9.3210e+00,  1.2436e+01,\n",
      "          1.3214e+01, -1.3101e+01,  8.3197e+00, -1.9074e+01, -4.1029e+00],\n",
      "        [-1.1769e+01, -9.9701e+00, -7.6935e-01, -1.0960e+00,  1.4027e+01,\n",
      "          8.2214e+00, -9.4384e+00, -6.1541e+00,  7.8180e-01, -8.8572e+00],\n",
      "        [-1.2541e+01, -6.5340e+00, -3.3130e+00, -1.2306e+01,  8.5518e+00,\n",
      "          7.7200e+00, -1.0837e+01,  4.4167e+00, -8.4781e+00, -2.8612e+00],\n",
      "        [-1.6406e+01, -7.1467e+00, -5.1944e+00, -1.1377e+01,  3.7263e+00,\n",
      "          1.5900e+00, -2.9788e+00, -3.2362e+00, -6.8928e+00, -1.0300e+00],\n",
      "        [-6.9304e+00, -7.6976e+00, -1.2750e+00, -1.2686e+01,  1.0835e+01,\n",
      "          1.1359e+01, -1.1001e+01, -3.5167e+00, -9.1185e+00, -4.4158e+00],\n",
      "        [-1.2779e+01, -9.6195e+00, -4.8839e-01, -9.4286e+00,  8.3805e+00,\n",
      "          4.1872e+00, -7.4507e-01, -4.5634e+00, -2.0931e+01, -2.1159e+00],\n",
      "        [-1.1432e+01, -5.8302e+00, -2.3003e-01, -5.8730e+00,  8.8012e+00,\n",
      "          4.1264e+00, -1.0292e+01,  3.6397e+00, -2.4175e+00, -8.5151e+00],\n",
      "        [-2.0133e+01, -3.7461e+00, -1.1428e+00, -1.2730e+00, -7.6125e-01,\n",
      "         -1.9224e+00, -5.2794e+00,  5.3954e+00, -1.9159e+01, -6.4360e+00],\n",
      "        [-1.6809e+01, -1.4594e+01, -1.0344e+01, -9.5518e+00,  1.0076e+01,\n",
      "          4.6905e+00, -2.4328e+00,  9.1718e+00, -7.1471e+00, -2.9920e+00],\n",
      "        [-1.3029e+01, -1.0317e+01,  1.7756e+00, -1.0182e+01,  1.1404e+01,\n",
      "          5.0611e+00, -5.6727e+00,  2.0812e+00, -8.3817e+00, -6.0546e+00],\n",
      "        [-1.1225e+01, -7.7159e+00, -2.2999e+00, -1.4755e+01,  1.8199e+00,\n",
      "          1.1572e+01, -4.8080e+00,  1.1014e+01, -9.2297e+00, -4.4883e+00],\n",
      "        [-5.0566e+00, -6.5657e+00, -2.6356e+00, -1.3552e+01,  9.6423e+00,\n",
      "          6.0033e+00, -1.3211e+01,  4.9753e-01, -4.3737e+00, -3.1456e+00],\n",
      "        [-1.9312e+01, -1.0772e+01, -5.1195e+00, -1.4042e+01, -1.5344e+00,\n",
      "          4.9333e+00, -1.3324e+01, -4.5647e+00, -1.4369e+01, -9.0207e-01],\n",
      "        [-1.5684e+01, -6.4527e+00, -1.0507e+01, -1.3631e+01,  1.3333e+01,\n",
      "          8.9024e+00, -1.2809e+01,  1.5012e+01, -1.0567e+01, -8.5937e+00],\n",
      "        [-1.5804e+01, -5.1580e+00, -1.0279e+00, -9.8776e+00,  3.3872e-01,\n",
      "          8.5235e+00, -6.3983e+00,  5.1545e+00, -9.2454e+00, -8.5871e+00],\n",
      "        [-1.8663e+01, -7.8733e+00,  5.9642e+00, -2.0184e+01,  1.2293e+01,\n",
      "          1.4046e+01, -5.8664e+00,  3.5377e+00, -8.3119e+00, -1.3060e+00],\n",
      "        [-8.6519e+00, -5.1524e+00, -2.2254e+00,  4.3195e+00,  1.4515e+01,\n",
      "          9.0332e+00, -3.2827e+00, -6.8541e+00, -1.5166e+01, -1.7812e+00],\n",
      "        [-1.2724e+01, -3.0370e+00,  4.3912e+00, -6.1081e+00,  1.0148e+01,\n",
      "          7.8441e-01, -7.5924e+00,  6.6283e+00, -6.7170e+00, -4.9170e+00],\n",
      "        [-2.0928e+01, -2.7870e+00,  3.1772e+00, -7.2361e+00,  1.0174e+01,\n",
      "          3.0502e+00,  2.1235e+00,  9.3798e+00, -1.0147e+01, -7.6387e+00],\n",
      "        [-9.6955e+00, -2.6474e+00, -1.1042e-02, -1.4841e+01,  2.4766e+00,\n",
      "          4.6579e+00, -1.1940e+01,  1.2089e+00, -1.7401e+01, -2.7452e+00],\n",
      "        [-1.0613e+01, -1.0785e+01,  1.4710e+00, -4.9982e+00,  1.6494e+01,\n",
      "          1.2426e+01, -4.7279e+00,  1.0793e+00, -7.7128e+00, -6.5083e-01],\n",
      "        [-1.4425e+01, -1.1303e+01, -6.7006e+00, -1.3672e+01,  9.1873e+00,\n",
      "          5.3314e+00, -8.0670e+00,  3.9231e+00, -1.4389e+01,  3.1300e-01],\n",
      "        [-1.6511e+01, -3.5639e+00,  6.3376e+00,  5.3112e+00,  2.2352e+00,\n",
      "          3.6873e+00, -1.4290e+01, -6.3080e+00, -1.0645e+01, -3.5646e+00],\n",
      "        [-5.8466e+00, -2.7850e+00,  3.1472e+00, -1.7881e+01,  1.0350e+01,\n",
      "          3.9740e+00, -6.8807e+00,  1.1702e+01, -6.3489e+00, -1.0925e+01],\n",
      "        [-2.3619e+01, -4.3189e+00, -4.4680e+00, -1.0581e+01,  1.6564e+01,\n",
      "          5.2425e+00, -7.4736e+00,  1.5299e+00, -1.2466e+01, -2.7637e+00],\n",
      "        [-1.6361e+01, -6.2779e+00,  1.4515e+00, -1.7008e+01,  4.6695e+00,\n",
      "          1.2696e+01,  4.7752e+00,  4.7360e+00, -1.8855e+01, -9.0436e+00],\n",
      "        [-5.2256e+00, -1.6584e+01,  5.8486e+00, -1.1604e+01,  8.6023e+00,\n",
      "          5.9566e+00, -5.5469e+00,  1.2849e+00, -1.0297e+01, -7.8961e+00],\n",
      "        [-1.2447e+01, -7.9240e+00,  5.6428e+00,  1.6684e-01,  5.5219e+00,\n",
      "          4.3231e+00, -1.5988e+01, -2.7818e+00, -1.1847e+01, -7.3276e+00],\n",
      "        [-1.5044e+01,  3.8124e+00,  4.3141e+00,  4.3172e+00,  5.3496e+00,\n",
      "          3.8739e+00, -7.7928e+00,  3.3600e+00, -7.3516e+00,  6.2155e-01],\n",
      "        [-1.6304e+01, -1.7903e+00,  7.6782e+00, -2.1193e+01,  1.2369e+01,\n",
      "          2.2077e+00,  3.4254e+00, -2.5836e+00, -1.5988e+01, -1.3026e+01],\n",
      "        [-1.2595e+01, -9.9673e+00,  5.0366e-01, -1.2299e+01, -1.3411e+00,\n",
      "          7.4479e+00, -3.7090e+00,  4.0516e+00, -1.6898e+01, -1.7116e+00],\n",
      "        [-8.7972e+00, -9.1066e+00, -5.0104e+00, -1.6505e+01,  2.0293e+00,\n",
      "          7.3875e+00, -7.9125e+00, -8.9371e+00, -5.0739e+00, -8.6771e+00],\n",
      "        [-1.6630e+01, -1.4654e+01, -1.0032e+01, -7.4926e+00,  9.4279e+00,\n",
      "          6.8662e-01, -7.2956e-02,  1.0543e+01, -8.4093e+00, -3.9335e+00],\n",
      "        [-1.6606e+01, -8.2212e+00,  4.6638e+00, -1.2041e+01,  1.3291e+01,\n",
      "          5.7200e+00,  1.0701e-01, -2.4916e+00, -1.0376e+01, -7.9471e+00],\n",
      "        [-8.8876e+00, -1.1727e+01, -1.5401e+00, -6.5566e+00,  1.6109e+01,\n",
      "          5.0381e+00, -6.0778e+00,  8.0557e+00, -1.1788e+01, -5.3951e+00],\n",
      "        [-5.8207e+00, -1.5261e+01, -3.0845e+00, -1.4512e+01,  8.6125e+00,\n",
      "          1.9186e+01,  8.2314e+00,  1.2954e+01, -1.7293e+01,  2.9305e-02],\n",
      "        [-1.3668e+01, -6.7694e+00, -7.0096e+00, -1.6532e+01,  2.4992e+00,\n",
      "          7.3274e+00, -7.3813e+00,  4.2851e+00, -1.3072e+01, -3.6398e+00],\n",
      "        [-1.5513e+01, -9.7342e+00,  5.0812e+00, -1.5749e+00,  2.7402e+00,\n",
      "          7.6591e+00,  2.3274e+00,  1.2214e+00, -2.8721e+00, -9.4758e+00],\n",
      "        [-1.2750e+01, -4.8116e+00, -2.6903e+00, -1.5145e+01,  2.3411e+00,\n",
      "          8.6132e+00, -9.7181e-01,  4.9920e+00, -1.2291e+01, -7.1655e+00],\n",
      "        [-1.3513e+01, -3.4257e+00,  1.6579e+00, -5.4256e+00,  5.7664e+00,\n",
      "          1.4211e+01,  5.3263e-01, -2.9349e+00, -1.6302e+01, -1.5205e+00],\n",
      "        [-1.0237e+01, -3.4184e+00, -3.7436e+00, -1.0461e+01,  7.5893e+00,\n",
      "          7.6863e+00, -7.7224e+00,  1.0886e+00, -9.7040e+00, -4.9448e+00],\n",
      "        [-1.7056e+01, -4.0591e+00, -3.8348e+00, -6.1366e+00,  3.8584e+00,\n",
      "          1.2497e+01, -2.5651e+00,  1.5478e+00, -1.7588e+01,  3.5160e+00],\n",
      "        [-1.0133e+01, -4.0601e+00,  5.1933e+00, -6.4885e+00,  1.0362e+01,\n",
      "         -5.3844e+00, -1.2178e+01, -6.6909e+00, -1.7119e+01, -1.2230e-01],\n",
      "        [-1.4549e+01, -7.4928e+00,  2.9841e+00, -9.9571e+00,  4.1982e+00,\n",
      "          1.2468e+01, -1.2082e+01,  5.0163e+00, -2.8042e+00, -6.4991e+00],\n",
      "        [-2.9003e+00, -6.7498e+00, -5.5881e+00, -1.4045e+01, -5.7378e+00,\n",
      "          1.1319e+01, -4.7330e+00,  5.4407e-01, -1.2613e+01, -1.5339e+00],\n",
      "        [-1.7724e+01, -5.8708e+00,  4.4431e-01, -6.2375e+00,  1.1349e+01,\n",
      "          3.9536e+00, -5.2408e+00, -2.7431e+00, -1.8428e+01, -4.0307e+00],\n",
      "        [-9.3321e+00, -1.9663e+00, -1.1648e+01, -8.2514e+00, -5.1902e-01,\n",
      "          1.1260e+00, -5.7095e-01, -1.7156e+00, -1.5209e+01,  1.1388e+01],\n",
      "        [-1.2173e+01, -1.3866e+01, -2.3097e+00, -1.0578e+01,  9.5643e+00,\n",
      "          3.4080e+00, -7.2943e+00, -8.0278e-01, -1.7706e+01, -8.9747e+00],\n",
      "        [-1.4289e+01, -7.9063e+00, -5.3460e-01, -1.8947e+01, -3.1046e-01,\n",
      "          7.1558e+00, -1.3746e+00,  4.0656e+00, -1.6628e+01, -4.5974e+00],\n",
      "        [-1.5453e+01, -1.9325e+00, -1.1205e+01, -6.9438e+00, -8.8706e+00,\n",
      "          1.0914e+01, -7.8634e+00, -2.2972e-01, -1.8530e+01, -6.3236e+00],\n",
      "        [-9.6236e+00, -6.8398e+00, -6.3207e+00, -1.0044e+01,  2.6306e+00,\n",
      "          1.4523e+00, -7.9747e+00, -5.3275e-01, -2.7970e+00,  1.3358e+00],\n",
      "        [-2.0059e+01, -1.7627e+00, -3.0263e-02, -2.3069e+01,  1.2407e+00,\n",
      "          8.7657e+00,  1.6059e+00,  3.4402e+00, -1.7844e+01, -3.4283e+00],\n",
      "        [-7.0948e+00, -4.3704e+00,  7.0309e-02, -1.3168e+01,  6.3887e+00,\n",
      "          1.3691e+01, -1.2357e+01, -1.7291e+00, -1.2301e+01, -3.1290e+00],\n",
      "        [-1.2830e+01, -5.4136e+00, -9.7582e+00, -8.2201e+00,  8.8353e+00,\n",
      "          5.7480e-02, -1.9130e+00, -5.9352e+00, -1.3126e+01, -6.4107e+00],\n",
      "        [-1.5925e+01, -1.1436e+01,  1.7395e+00, -7.2364e+00,  1.4500e+01,\n",
      "          3.7587e+00,  3.0673e+00, -5.4112e+00, -1.1735e+01, -4.3627e+00],\n",
      "        [-7.5103e+00, -1.3554e+01, -1.3268e+01, -8.7786e+00,  7.6791e+00,\n",
      "          7.6262e+00, -9.6045e+00,  9.8289e+00, -1.6658e+01, -3.6854e+00],\n",
      "        [-1.7352e+01, -6.9706e+00,  2.8602e+00, -2.1518e+00, -1.2875e+00,\n",
      "          1.1140e+01, -2.8046e+00, -1.2251e+01, -1.4003e+01,  1.0386e+00],\n",
      "        [-1.1074e+01, -1.4284e+01,  1.1981e+00, -1.0862e+01,  6.9243e+00,\n",
      "          4.9114e+00, -2.3681e+00,  1.0874e-01, -6.8948e+00, -6.3903e+00],\n",
      "        [-1.6416e+01, -4.6899e+00,  1.4442e+00, -4.6162e+00,  1.3137e+01,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         -1.3250e+00, -1.1072e+01, -1.9064e-01, -1.6912e+01, -1.7962e+00]])\n"
     ]
    }
   ],
   "source": [
    "## Solution\n",
    "torch.manual_seed(7) # Set the random seed so things are predictable\n",
    "\n",
    "\n",
    "def activation(x):\n",
    "    return 1/(1+torch.exp(-x))\n",
    "\n",
    "# Flatten the input images\n",
    "inputs = images.view(images.shape[0], -1)\n",
    "\n",
    "# Create parameters\n",
    "### Generate some data\n",
    "# torch.manual_seed(1) # Set the random seed so things are predictable\n",
    "w1 = torch.randn(784, 256)\n",
    "### Generate some data\n",
    "# torch.manual_seed(3) # Set the random seed so things are predictable\n",
    "\n",
    "\n",
    "### Generate some data\n",
    "# torch.manual_seed(2) # Set the random seed so things are predictable\n",
    "w2 = torch.randn(256, 10)\n",
    "### Generate some data\n",
    "# torch.manual_seed(4) # Set the random seed so things are predictable\n",
    "\n",
    "b1 = torch.randn(256)\n",
    "\n",
    "\n",
    "b2 = torch.randn(10)\n",
    "\n",
    "h = activation(torch.mm(inputs, w1) + b1)\n",
    "\n",
    "out = torch.mm(h, w2) + b2\n",
    "\n",
    "print('out_shape:', out.shape)\n",
    "\n",
    "print('out:', out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([784, 256])\n",
      "tensor([[-0.8201,  0.3956,  0.8989,  ..., -0.8095,  0.0931, -0.3004],\n",
      "        [ 0.0063, -1.5065, -0.6245,  ...,  0.2500, -0.8542,  0.4376],\n",
      "        [ 0.3811,  0.3953, -1.5423,  ...,  0.8410,  0.6489,  0.0831],\n",
      "        ...,\n",
      "        [-0.2211,  2.2698,  0.3598,  ...,  1.1744,  0.1071, -0.5518],\n",
      "        [-0.5600,  0.3535,  0.1987,  ..., -0.3272,  0.7141,  0.3582],\n",
      "        [-0.1653, -1.2431,  0.6112,  ...,  1.0518, -0.8067, -0.7709]])\n"
     ]
    }
   ],
   "source": [
    "print(w1.shape)\n",
    "print(w1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([256, 10])\n",
      "tensor([[ 0.6339,  1.0345,  0.3033,  ..., -0.1860, -0.6364,  2.1867],\n",
      "        [ 1.3871, -0.3107, -2.7180,  ..., -0.1921, -1.2932, -0.7217],\n",
      "        [-0.8895, -0.3219, -0.0805,  ...,  0.6811, -1.0980, -1.3810],\n",
      "        ...,\n",
      "        [-0.5285,  2.4616, -0.3759,  ..., -1.0795, -0.5645, -1.3539],\n",
      "        [ 0.2632, -2.2103,  0.9946,  ...,  0.0997,  0.6885,  1.9427],\n",
      "        [ 0.4363, -0.9149, -1.5136,  ..., -0.7218, -0.9097, -0.7107]])\n"
     ]
    }
   ],
   "source": [
    "print(w2.shape)\n",
    "print(w2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([256])\n",
      "tensor([ 0.7149,  0.6391, -0.9468,  0.6111,  1.5337,  0.1529,  1.5468, -0.9979,\n",
      "         2.1075, -1.9619,  0.5851, -0.0518, -0.0596, -0.0039,  2.4317, -0.8046,\n",
      "        -0.0613,  0.8964, -0.1711,  0.4709, -0.4805,  0.6235, -0.1567, -0.1102,\n",
      "         1.2652, -1.6166, -0.2357,  0.1173,  1.3401,  1.4215,  0.7395,  0.1019,\n",
      "        -0.9962,  1.0348,  1.7533, -2.3131, -0.0257, -0.5041,  0.8696,  0.3856,\n",
      "         0.4578, -0.8792,  0.8854,  1.1591,  1.6646, -0.2215,  0.9049, -0.1276,\n",
      "        -0.5799, -0.5257,  0.0240,  0.2594, -1.8826,  1.3392,  0.7814,  2.2156,\n",
      "         1.2746, -0.5243, -0.4295, -0.3225, -1.1501,  0.4566,  1.0014, -2.8142,\n",
      "        -0.1465,  0.3128, -0.5625,  0.0347,  0.1021, -0.9091,  0.0979,  0.9576,\n",
      "        -0.2307,  0.5282,  2.5405,  1.4265,  1.4662, -0.9381, -0.3563, -0.2176,\n",
      "        -0.7131,  0.2172, -0.2947, -0.9215, -0.2526, -1.3041, -0.9596,  0.6026,\n",
      "         0.2500,  0.2582, -1.0267,  0.0261, -0.4179,  1.2987,  2.5355, -0.1682,\n",
      "        -0.7441, -0.0480,  0.7085, -1.0430,  1.6970,  0.1162, -0.0150, -1.6518,\n",
      "         0.0034, -0.4086, -2.3391, -0.7113,  1.1904,  0.9898, -1.4300,  0.6581,\n",
      "        -1.6350,  0.7007, -0.0614, -0.0600, -0.4891, -2.4256, -0.0463,  1.2095,\n",
      "        -0.0635, -1.5256, -0.0985, -0.8564,  1.1518, -1.1931,  1.3311,  0.4637,\n",
      "         0.5104,  0.9343,  2.7530,  0.8304, -0.7449,  0.9520, -0.6101,  0.0037,\n",
      "         1.5588,  0.5781,  1.6157,  1.1864, -0.1059,  0.8955,  0.5089, -0.5682,\n",
      "         0.5934, -1.4285,  0.4242,  0.3133,  0.9954, -0.6814,  1.6840,  0.2694,\n",
      "         0.2489,  1.2575, -0.2049, -0.9840,  1.2153,  0.0435,  0.1597,  0.9136,\n",
      "         1.1404,  0.4976,  2.4049, -1.2975, -0.7476,  2.5345,  0.7615,  1.0451,\n",
      "         0.5536,  0.9991,  0.5526, -0.0721, -3.0442, -1.8129, -0.8466, -1.9117,\n",
      "         0.0989,  1.0894,  1.0988, -0.3363,  0.9586,  0.2918,  0.2559,  0.7558,\n",
      "        -0.7602, -1.8358,  0.3545, -0.5371, -0.5341,  1.5675, -0.4118,  1.1028,\n",
      "        -2.1238, -0.5777,  1.0439, -2.7941,  1.3027,  0.8645,  1.2941,  1.1189,\n",
      "         1.1336, -0.7071,  0.8700, -2.1905, -1.1429,  0.7345, -1.0534,  0.1086,\n",
      "        -2.3883,  0.0468,  1.3603,  0.4944, -0.6741,  0.4602, -0.8606,  2.0539,\n",
      "         0.4668,  0.3952, -0.6453,  0.3608, -0.2328, -0.2933, -2.0921,  1.4156,\n",
      "        -1.1043, -0.2244, -1.2447, -1.1257,  1.9774, -0.7801, -0.6585,  0.0824,\n",
      "        -0.0792,  0.0413,  1.5400,  1.7533, -2.0053, -0.5925, -0.9915, -1.4284,\n",
      "        -0.6961,  1.1634, -0.9546,  1.7595, -1.1099, -0.6329, -0.7099, -0.2695,\n",
      "         1.6135,  0.9572, -0.5114,  0.8759, -0.0380, -0.4646, -0.8043,  1.1730])\n"
     ]
    }
   ],
   "source": [
    "print(b1.shape)\n",
    "print(b1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10])\n",
      "tensor([ 2.3840, -1.6445,  1.6947, -0.0045,  0.4340, -0.8494, -1.2688,  0.4180,\n",
      "        -0.2822,  0.0992])\n"
     ]
    }
   ],
   "source": [
    "print(b2.shape)\n",
    "print(b2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have 10 outputs for our network. We want to pass in an image to our network and get out a probability distribution over the classes that tells us the likely class(es) the image belongs to. Something that looks like this:\n",
    "<img src='assets/image_distribution.png' width=500px>\n",
    "\n",
    "Here we see that the probability for each class is roughly the same. This is representing an untrained network, it hasn't seen any data yet so it just returns a uniform distribution with equal probabilities for each class.\n",
    "\n",
    "To calculate this probability distribution, we often use the [**softmax** function](https://en.wikipedia.org/wiki/Softmax_function). Mathematically this looks like\n",
    "\n",
    "$$\n",
    "\\Large \\sigma(x_i) = \\cfrac{e^{x_i}}{\\sum_k^K{e^{x_k}}}\n",
    "$$\n",
    "\n",
    "What this does is squish each input $x_i$ between 0 and 1 and normalizes the values to give you a proper probability distribution where the probabilites sum up to one.\n",
    "\n",
    "> **Exercise:** Implement a function `softmax` that performs the softmax calculation and returns probability distributions for each example in the batch. Note that you'll need to pay attention to the shapes when doing this. If you have a tensor `a` with shape `(64, 10)` and a tensor `b` with shape `(64,)`, doing `a/b` will give you an error because PyTorch will try to do the division across the columns (called broadcasting) but you'll get a size mismatch. The way to think about this is for each of the 64 examples, you only want to divide by one value, the sum in the denominator. So you need `b` to have a shape of `(64, 1)`. This way PyTorch will divide the 10 values in each row of `a` by the one value in each row of `b`. Pay attention to how you take the sum as well. You'll need to define the `dim` keyword in `torch.sum`. Setting `dim=0` takes the sum across the rows while `dim=1` takes the sum across the columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 10])\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000])\n"
     ]
    }
   ],
   "source": [
    "## Solution\n",
    "def softmax(x):\n",
    "    return torch.exp(x)/torch.sum(torch.exp(x), dim=1).view(-1, 1)\n",
    "\n",
    "probabilities = softmax(out)\n",
    "\n",
    "# Does it have the right shape? Should be (64, 10)\n",
    "print(probabilities.shape)\n",
    "# Does it sum to 1?\n",
    "print(probabilities.sum(dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2.7838e-13, 5.4893e-12, 3.2414e-07, 6.6895e-11, 7.5817e-01, 2.4183e-01,\n",
       "         1.3911e-13, 1.4602e-08, 9.3669e-12, 4.2744e-09],\n",
       "        [9.3579e-11, 2.6458e-10, 1.6629e-04, 3.5256e-06, 9.8913e-01, 8.3044e-03,\n",
       "         4.9717e-05, 1.9016e-03, 1.9315e-09, 4.4482e-04],\n",
       "        [7.5866e-08, 6.3664e-09, 3.7452e-05, 6.2106e-09, 2.1248e-01, 8.2333e-02,\n",
       "         8.8114e-08, 6.4753e-01, 2.9743e-13, 5.7619e-02],\n",
       "        [3.8505e-12, 1.0991e-09, 2.2220e-04, 1.2457e-10, 5.7548e-01, 3.4032e-01,\n",
       "         1.7816e-04, 8.3795e-02, 3.5050e-10, 4.9460e-09],\n",
       "        [1.8959e-13, 1.9375e-10, 6.2814e-07, 3.7369e-13, 2.9423e-01, 1.7861e-03,\n",
       "         4.6197e-06, 7.0397e-01, 1.7557e-11, 1.0545e-11],\n",
       "        [1.4237e-10, 5.1340e-08, 2.5297e-07, 1.1138e-10, 3.1326e-01, 6.8163e-01,\n",
       "         2.5414e-12, 5.1054e-03, 6.4736e-15, 2.0558e-08],\n",
       "        [6.2454e-12, 3.7733e-11, 3.7374e-07, 2.6958e-07, 9.9700e-01, 3.0006e-03,\n",
       "         6.4217e-11, 1.7140e-09, 1.7629e-06, 1.1483e-10],\n",
       "        [4.7619e-10, 1.9345e-07, 4.8463e-06, 6.0227e-10, 6.8905e-01, 2.9991e-01,\n",
       "         2.6164e-09, 1.1026e-02, 2.7686e-08, 7.6146e-06],\n",
       "        [1.5991e-09, 1.6797e-05, 1.1832e-04, 2.4436e-07, 8.8571e-01, 1.0459e-01,\n",
       "         1.0847e-03, 8.3853e-04, 2.1651e-05, 7.6150e-03],\n",
       "        [7.1640e-09, 3.3265e-09, 2.0477e-06, 2.2667e-11, 3.7192e-01, 6.2808e-01,\n",
       "         1.2224e-10, 2.1763e-07, 8.0330e-10, 8.8563e-08],\n",
       "        [6.3645e-10, 1.4999e-08, 1.3856e-04, 1.8153e-08, 9.8486e-01, 1.4867e-02,\n",
       "         1.0719e-04, 2.3546e-06, 1.8353e-13, 2.7217e-05],\n",
       "        [1.6085e-09, 4.3564e-07, 1.1783e-04, 4.1738e-07, 9.8503e-01, 9.1882e-03,\n",
       "         5.0257e-09, 5.6473e-03, 1.3220e-05, 2.9721e-08],\n",
       "        [8.1390e-12, 1.0653e-04, 1.4389e-03, 1.2633e-03, 2.1074e-03, 6.5990e-04,\n",
       "         2.2991e-05, 9.9439e-01, 2.1556e-11, 7.2316e-06],\n",
       "        [1.4953e-12, 1.3705e-11, 9.6106e-10, 2.1214e-09, 7.0954e-01, 3.2508e-03,\n",
       "         2.6204e-06, 2.8721e-01, 2.3495e-08, 1.4980e-06],\n",
       "        [2.4424e-11, 3.6805e-10, 6.5699e-05, 4.2125e-10, 9.9809e-01, 1.7557e-03,\n",
       "         3.8265e-08, 8.9184e-05, 2.5488e-09, 2.6120e-08],\n",
       "        [7.9955e-11, 2.6716e-09, 6.0106e-07, 2.3436e-12, 3.6992e-05, 6.3589e-01,\n",
       "         4.8940e-08, 3.6408e-01, 5.8791e-10, 6.7373e-08],\n",
       "        [4.0274e-07, 8.9054e-08, 4.5340e-06, 8.2320e-11, 9.7428e-01, 2.5603e-02,\n",
       "         1.1579e-10, 1.0403e-04, 7.9730e-07, 2.7226e-06],\n",
       "        [2.9397e-11, 1.5045e-07, 4.2868e-05, 5.7151e-09, 1.5457e-03, 9.9543e-01,\n",
       "         1.1717e-08, 7.4660e-05, 4.1218e-09, 2.9089e-03],\n",
       "        [3.9250e-14, 4.0075e-10, 6.9507e-12, 3.0589e-13, 1.5690e-01, 1.8687e-03,\n",
       "         6.9584e-13, 8.4124e-01, 6.5452e-12, 4.7102e-11],\n",
       "        [2.6286e-11, 1.1050e-06, 6.8715e-05, 9.8555e-09, 2.6950e-04, 9.6639e-01,\n",
       "         3.1968e-07, 3.3267e-02, 1.8545e-08, 3.5821e-08],\n",
       "        [5.3115e-15, 2.5773e-10, 2.6346e-04, 1.1606e-15, 1.4764e-01, 8.5207e-01,\n",
       "         1.9177e-09, 2.3276e-05, 1.6623e-10, 1.8336e-07],\n",
       "        [8.6444e-11, 2.8613e-09, 5.3422e-08, 3.7166e-05, 9.9582e-01, 4.1428e-03,\n",
       "         1.8559e-08, 5.2181e-10, 1.2816e-13, 8.3303e-08],\n",
       "        [1.1289e-10, 1.8189e-06, 3.0609e-03, 8.4346e-08, 9.6818e-01, 8.3068e-05,\n",
       "         1.9118e-08, 2.8669e-02, 4.5877e-08, 2.7756e-07],\n",
       "        [2.1373e-14, 1.6165e-06, 6.2921e-04, 1.8897e-08, 6.8773e-01, 5.5419e-04,\n",
       "         2.1938e-04, 3.1087e-01, 1.0283e-09, 1.2634e-08],\n",
       "        [5.0546e-07, 5.8164e-04, 8.1209e-03, 2.9461e-09, 9.7716e-02, 8.6555e-01,\n",
       "         5.3561e-08, 2.7507e-02, 2.2757e-10, 5.2745e-04],\n",
       "        [1.6601e-12, 1.3982e-12, 2.9390e-07, 4.5565e-10, 9.8317e-01, 1.6827e-02,\n",
       "         5.9711e-10, 1.9864e-07, 3.0179e-11, 3.5212e-08],\n",
       "        [5.4194e-11, 1.2293e-09, 1.2264e-07, 1.1509e-10, 9.7421e-01, 2.0610e-02,\n",
       "         3.1276e-08, 5.0404e-03, 5.6199e-11, 1.3633e-04],\n",
       "        [8.2563e-11, 3.4659e-05, 6.9178e-01, 2.4786e-01, 1.1437e-02, 4.8860e-02,\n",
       "         7.6095e-10, 2.2288e-06, 2.9138e-08, 3.4636e-05],\n",
       "        [1.8996e-08, 4.0580e-07, 1.5297e-04, 1.1273e-13, 2.0539e-01, 3.4972e-04,\n",
       "         6.7540e-09, 7.9411e-01, 1.1496e-08, 1.1830e-10],\n",
       "        [3.5402e-18, 8.5257e-10, 7.3451e-10, 1.6259e-12, 9.9999e-01, 1.2112e-05,\n",
       "         3.6366e-11, 2.9570e-07, 2.4691e-13, 4.0380e-09],\n",
       "        [2.3991e-13, 5.7420e-09, 1.3060e-05, 1.2561e-13, 3.2620e-04, 9.9895e-01,\n",
       "         3.6256e-04, 3.4863e-04, 1.9806e-14, 3.6137e-10],\n",
       "        [8.6998e-07, 1.0149e-11, 5.6104e-02, 1.4772e-09, 8.8081e-01, 6.2501e-02,\n",
       "         6.3092e-07, 5.8477e-04, 5.4593e-09, 6.0220e-08],\n",
       "        [6.4488e-09, 5.9429e-07, 4.6346e-01, 1.9401e-03, 4.1066e-01, 1.2384e-01,\n",
       "         1.8699e-10, 1.0168e-04, 1.1751e-08, 1.0790e-06],\n",
       "        [6.0451e-10, 9.3455e-02, 1.5434e-01, 1.5482e-01, 4.3471e-01, 9.9380e-02,\n",
       "         8.5218e-07, 5.9446e-02, 1.3247e-06, 3.8444e-03],\n",
       "        [3.4966e-13, 7.0271e-07, 9.0971e-03, 2.6308e-15, 9.9073e-01, 3.8290e-05,\n",
       "         1.2940e-04, 3.1789e-07, 4.7966e-13, 9.2726e-12],\n",
       "        [1.9074e-09, 2.6414e-08, 9.3178e-04, 2.5656e-09, 1.4728e-04, 9.6644e-01,\n",
       "         1.3797e-05, 3.2370e-02, 2.5806e-11, 1.0168e-04],\n",
       "        [9.3115e-08, 6.8338e-08, 4.1081e-06, 4.1853e-11, 4.6874e-03, 9.9530e-01,\n",
       "         2.2556e-07, 8.0959e-08, 3.8552e-06, 1.0501e-07],\n",
       "        [1.1906e-12, 8.5845e-12, 8.7323e-10, 1.1066e-08, 2.4688e-01, 3.9463e-05,\n",
       "         1.8463e-05, 7.5306e-01, 4.4246e-09, 3.8876e-07],\n",
       "        [1.0366e-13, 4.5385e-10, 1.7896e-04, 9.9514e-12, 9.9930e-01, 5.1461e-04,\n",
       "         1.8784e-06, 1.3972e-07, 5.2631e-11, 5.9698e-10],\n",
       "        [1.3927e-11, 8.1406e-13, 2.1618e-08, 1.4328e-10, 9.9967e-01, 1.5548e-05,\n",
       "         2.3126e-10, 3.1785e-04, 7.6605e-13, 4.5772e-10],\n",
       "        [1.3766e-11, 1.0936e-15, 2.1238e-10, 2.3125e-15, 2.5532e-05, 9.9799e-01,\n",
       "         1.7440e-05, 1.9621e-03, 1.4334e-16, 4.7801e-09],\n",
       "        [7.2131e-10, 7.1496e-07, 5.6228e-07, 4.1145e-11, 7.5788e-03, 9.4720e-01,\n",
       "         3.8773e-07, 4.5207e-02, 1.3096e-09, 1.6347e-05],\n",
       "        [7.9291e-11, 2.5636e-08, 6.9677e-02, 8.9616e-05, 6.7050e-03, 9.1760e-01,\n",
       "         4.4375e-03, 1.4683e-03, 2.4493e-05, 3.3196e-08],\n",
       "        [5.1254e-10, 1.4368e-06, 1.1985e-05, 4.6738e-11, 1.8356e-03, 9.7208e-01,\n",
       "         6.6834e-05, 2.6003e-02, 8.1148e-10, 1.3649e-07],\n",
       "        [9.1126e-13, 2.1906e-08, 3.5344e-06, 2.9646e-09, 2.1510e-04, 9.9978e-01,\n",
       "         1.1471e-06, 3.5783e-08, 5.6010e-14, 1.4722e-07],\n",
       "        [8.6151e-09, 7.8795e-06, 5.6922e-06, 6.8834e-09, 4.7541e-01, 5.2386e-01,\n",
       "         1.0649e-07, 7.1429e-04, 1.4679e-08, 1.7123e-06],\n",
       "        [1.4629e-13, 6.4524e-08, 8.0748e-08, 8.0806e-09, 1.7711e-04, 9.9968e-01,\n",
       "         2.8744e-07, 1.7569e-05, 8.5977e-14, 1.2576e-04],\n",
       "        [1.2500e-09, 5.4224e-07, 5.6611e-03, 4.7815e-08, 9.9431e-01, 1.4423e-07,\n",
       "         1.6171e-10, 3.9053e-08, 1.1558e-12, 2.7820e-05],\n",
       "        [1.8466e-12, 2.1426e-09, 7.6029e-05, 1.8226e-10, 2.5601e-04, 9.9909e-01,\n",
       "         2.1778e-11, 5.8019e-04, 2.3291e-07, 5.7877e-09],\n",
       "        [6.6763e-07, 1.4213e-08, 4.5419e-08, 9.6442e-12, 3.9103e-08, 9.9998e-01,\n",
       "         1.0680e-07, 2.0912e-05, 4.0392e-11, 2.6178e-06],\n",
       "        [2.3630e-13, 3.3213e-08, 1.8362e-05, 2.3017e-08, 9.9937e-01, 6.1374e-04,\n",
       "         6.2360e-08, 7.5799e-07, 1.1690e-13, 2.0915e-07],\n",
       "        [1.0035e-09, 1.5865e-06, 9.9028e-11, 2.9572e-09, 6.7452e-06, 3.4947e-05,\n",
       "         6.4039e-06, 2.0387e-06, 2.8126e-12, 9.9995e-01],\n",
       "        [3.6208e-10, 6.6592e-11, 6.9542e-06, 1.7834e-09, 9.9785e-01, 2.1155e-03,\n",
       "         4.7587e-08, 3.1384e-05, 1.4317e-12, 8.8647e-09],\n",
       "        [4.6436e-10, 2.7466e-07, 4.3679e-04, 4.4060e-12, 5.4653e-04, 9.5536e-01,\n",
       "         1.8857e-04, 4.3464e-02, 4.4779e-11, 7.5131e-06],\n",
       "        [3.5387e-12, 2.6342e-06, 2.4766e-10, 1.7549e-08, 2.5554e-09, 9.9998e-01,\n",
       "         6.9966e-09, 1.4460e-05, 1.6306e-13, 3.2629e-08],\n",
       "        [2.9256e-06, 4.7340e-05, 7.9551e-05, 1.9222e-06, 6.1400e-01, 1.8899e-01,\n",
       "         1.5216e-05, 2.5961e-02, 2.6976e-03, 1.6821e-01],\n",
       "        [3.0128e-13, 2.6594e-05, 1.5038e-04, 1.4845e-14, 5.3598e-04, 9.9367e-01,\n",
       "         7.7226e-04, 4.8351e-03, 2.7603e-12, 5.0285e-06],\n",
       "        [9.3912e-10, 1.4319e-08, 1.2147e-06, 2.1628e-12, 6.7378e-04, 9.9932e-01,\n",
       "         4.8684e-12, 2.0090e-07, 5.1482e-12, 4.9549e-08],\n",
       "        [3.8978e-10, 6.4819e-07, 8.4117e-09, 3.9163e-08, 9.9982e-01, 1.5409e-04,\n",
       "         2.1479e-05, 3.8477e-07, 2.8984e-10, 2.3916e-07],\n",
       "        [6.1203e-14, 5.4480e-12, 2.8728e-06, 3.6318e-10, 9.9996e-01, 2.1640e-05,\n",
       "         1.0839e-05, 2.2533e-09, 4.0405e-12, 6.4292e-09],\n",
       "        [2.4034e-08, 5.7040e-11, 7.5925e-11, 6.7610e-09, 9.4959e-02, 9.0065e-02,\n",
       "         2.9603e-09, 8.1498e-01, 2.5588e-12, 1.1015e-06],\n",
       "        [4.2266e-13, 1.3636e-08, 2.5362e-04, 1.6884e-06, 4.0073e-06, 9.9970e-01,\n",
       "         8.7896e-07, 6.9435e-11, 1.2039e-11, 4.1026e-05],\n",
       "        [1.3402e-08, 5.4099e-10, 2.8639e-03, 1.6563e-08, 8.7870e-01, 1.1739e-01,\n",
       "         8.0945e-05, 9.6352e-04, 8.7554e-07, 1.4501e-06],\n",
       "        [1.4628e-13, 1.8100e-08, 8.3500e-06, 1.9485e-08, 9.9999e-01, 5.2367e-07,\n",
       "         3.0609e-11, 1.6281e-06, 8.9082e-14, 3.2688e-07]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building networks with PyTorch\n",
    "\n",
    "PyTorch provides a module `nn` that makes building networks much simpler. Here I'll show you how to build the same one as above with 784 inputs, 256 hidden units, 10 output units and a softmax output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Inputs to hidden layer linear transformation\n",
    "        self.hidden = nn.Linear(784, 256)\n",
    "        # Output layer, 10 units - one for each digit\n",
    "        self.output = nn.Linear(256, 10)\n",
    "        \n",
    "        # Define sigmoid activation and softmax output \n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Pass the input tensor through each of our operations\n",
    "        x = self.hidden(x)\n",
    "        x = self.sigmoid(x)\n",
    "        x = self.output(x)\n",
    "        x = self.softmax(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's go through this bit by bit.\n",
    "\n",
    "```python\n",
    "class Network(nn.Module):\n",
    "```\n",
    "\n",
    "Here we're inheriting from `nn.Module`. Combined with `super().__init__()` this creates a class that tracks the architecture and provides a lot of useful methods and attributes. It is mandatory to inherit from `nn.Module` when you're creating a class for your network. The name of the class itself can be anything.\n",
    "\n",
    "```python\n",
    "self.hidden = nn.Linear(784, 256)\n",
    "```\n",
    "\n",
    "This line creates a module for a linear transformation, $x\\mathbf{W} + b$, with 784 inputs and 256 outputs and assigns it to `self.hidden`. The module automatically creates the weight and bias tensors which we'll use in the `forward` method. You can access the weight and bias tensors once the network (`net`) is created with `net.hidden.weight` and `net.hidden.bias`.\n",
    "\n",
    "```python\n",
    "self.output = nn.Linear(256, 10)\n",
    "```\n",
    "\n",
    "Similarly, this creates another linear transformation with 256 inputs and 10 outputs.\n",
    "\n",
    "```python\n",
    "self.sigmoid = nn.Sigmoid()\n",
    "self.softmax = nn.Softmax(dim=1)\n",
    "```\n",
    "\n",
    "Here I defined operations for the sigmoid activation and softmax output. Setting `dim=1` in `nn.Softmax(dim=1)` calculates softmax across the columns.\n",
    "\n",
    "```python\n",
    "def forward(self, x):\n",
    "```\n",
    "\n",
    "PyTorch networks created with `nn.Module` must have a `forward` method defined. It takes in a tensor `x` and passes it through the operations you defined in the `__init__` method.\n",
    "\n",
    "```python\n",
    "x = self.hidden(x)\n",
    "x = self.sigmoid(x)\n",
    "x = self.output(x)\n",
    "x = self.softmax(x)\n",
    "```\n",
    "\n",
    "Here the input tensor `x` is passed through each operation a reassigned to `x`. We can see that the input tensor goes through the hidden layer, then a sigmoid function, then the output layer, and finally the softmax function. It doesn't matter what you name the variables here, as long as the inputs and outputs of the operations match the network architecture you want to build. The order in which you define things in the `__init__` method doesn't matter, but you'll need to sequence the operations correctly in the `forward` method.\n",
    "\n",
    "Now we can create a `Network` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Network(\n",
       "  (hidden): Linear(in_features=784, out_features=256, bias=True)\n",
       "  (output): Linear(in_features=256, out_features=10, bias=True)\n",
       "  (sigmoid): Sigmoid()\n",
       "  (softmax): Softmax(dim=1)\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the network and look at it's text representation\n",
    "model = Network()\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can define the network somewhat more concisely and clearly using the `torch.nn.functional` module. This is the most common way you'll see networks defined as many operations are simple element-wise functions. We normally import this module as `F`, `import torch.nn.functional as F`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "class Network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # Inputs to hidden layer linear transformation\n",
    "        self.hidden = nn.Linear(784, 256)\n",
    "        # Output layer, 10 units - one for each digit\n",
    "        self.output = nn.Linear(256, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Hidden layer with sigmoid activation\n",
    "        x = F.sigmoid(self.hidden(x))\n",
    "        # Output layer with softmax activation\n",
    "        x = F.softmax(self.output(x), dim=1)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Activation functions\n",
    "\n",
    "So far we've only been looking at the softmax activation, but in general any function can be used as an activation function. The only requirement is that for a network to approximate a non-linear function, the activation functions must be non-linear. Here are a few more examples of common activation functions: Tanh (hyperbolic tangent), and ReLU (rectified linear unit).\n",
    "\n",
    "<img src=\"assets/activation.png\" width=700px>\n",
    "\n",
    "In practice, the ReLU function is used almost exclusively as the activation function for hidden layers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your Turn to Build a Network\n",
    "\n",
    "<img src=\"assets/mlp_mnist.png\" width=600px>\n",
    "\n",
    "> **Exercise:** Create a network with 784 input units, a hidden layer with 128 units and a ReLU activation, then a hidden layer with 64 units and a ReLU activation, and finally an output layer with a softmax activation as shown above. You can use a ReLU activation with the `nn.ReLU` module or `F.relu` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Network(\n",
       "  (fc1): Linear(in_features=784, out_features=128, bias=True)\n",
       "  (fc2): Linear(in_features=128, out_features=64, bias=True)\n",
       "  (fc3): Linear(in_features=64, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Solution\n",
    "torch.manual_seed(7) \n",
    "class Network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # Defining the layers, 128, 64, 10 units each\n",
    "        self.fc1 = nn.Linear(784, 128)\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        # Output layer, 10 units - one for each digit\n",
    "        self.fc3 = nn.Linear(64, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        ''' Forward pass through the network, returns the output logits '''\n",
    "        \n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc3(x)\n",
    "        x = F.softmax(x, dim=1)\n",
    "        \n",
    "        return x\n",
    "\n",
    "model = Network()\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initializing weights and biases\n",
    "\n",
    "The weights and such are automatically initialized for you, but it's possible to customize how they are initialized. The weights and biases are tensors attached to the layer you defined, you can get them with `model.fc1.weight` for instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[ 2.4945e-03, -2.1514e-02,  1.1372e-02,  ...,  2.3490e-02,\n",
      "         -3.4548e-02,  2.3653e-02],\n",
      "        [ 3.3077e-05, -2.2735e-02, -1.0311e-02,  ...,  1.7026e-02,\n",
      "         -1.3917e-02, -2.0039e-02],\n",
      "        [-1.6752e-02, -1.9683e-02, -1.9263e-02,  ...,  6.4771e-03,\n",
      "         -1.4055e-02,  1.4966e-02],\n",
      "        ...,\n",
      "        [-3.4493e-02,  3.3553e-02, -2.7586e-02,  ...,  6.2408e-03,\n",
      "         -1.1582e-02, -1.4566e-02],\n",
      "        [-2.1782e-03, -4.6771e-03, -1.3024e-02,  ...,  2.8419e-02,\n",
      "         -1.2565e-02,  3.0100e-03],\n",
      "        [-1.0337e-02, -2.4091e-02, -2.5221e-02,  ...,  1.0698e-02,\n",
      "         -3.1701e-02,  3.2672e-02]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.0048, -0.0146,  0.0170,  0.0262, -0.0180,  0.0002, -0.0306, -0.0086,\n",
      "        -0.0222, -0.0325,  0.0004,  0.0012, -0.0320,  0.0124,  0.0130,  0.0235,\n",
      "         0.0311, -0.0310,  0.0150, -0.0296,  0.0220,  0.0164,  0.0282,  0.0216,\n",
      "        -0.0355, -0.0038, -0.0210, -0.0240,  0.0301, -0.0138,  0.0031,  0.0295,\n",
      "        -0.0106,  0.0031, -0.0215,  0.0151,  0.0090, -0.0110,  0.0284,  0.0247,\n",
      "        -0.0335, -0.0092, -0.0027, -0.0280, -0.0119, -0.0193, -0.0145, -0.0141,\n",
      "        -0.0332,  0.0100,  0.0156, -0.0154,  0.0335, -0.0224,  0.0312, -0.0212,\n",
      "         0.0174,  0.0226,  0.0108,  0.0066,  0.0064, -0.0015, -0.0161,  0.0175,\n",
      "        -0.0208,  0.0196, -0.0174,  0.0238, -0.0019,  0.0146, -0.0068, -0.0009,\n",
      "        -0.0348,  0.0228, -0.0059,  0.0044, -0.0046,  0.0113,  0.0167, -0.0026,\n",
      "         0.0091,  0.0111, -0.0078, -0.0003, -0.0232,  0.0200,  0.0167,  0.0272,\n",
      "        -0.0278, -0.0339, -0.0076, -0.0169, -0.0103,  0.0089,  0.0018, -0.0067,\n",
      "         0.0166, -0.0196, -0.0282, -0.0259,  0.0253,  0.0068,  0.0188,  0.0041,\n",
      "         0.0024,  0.0023,  0.0006, -0.0332,  0.0172, -0.0315,  0.0166,  0.0339,\n",
      "         0.0275, -0.0338, -0.0051,  0.0041, -0.0198,  0.0338, -0.0163, -0.0176,\n",
      "         0.0160,  0.0178, -0.0235,  0.0162, -0.0107,  0.0323, -0.0145,  0.0042],\n",
      "       requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(model.fc1.weight)\n",
    "print(model.fc1.bias)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For custom initialization, we want to modify these tensors in place. These are actually autograd *Variables*, so we need to get back the actual tensors with `model.fc1.weight.data`. Once we have the tensors, we can fill them with zeros (for biases) or random normal values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set biases to all zeros\n",
    "model.fc1.bias.data.fill_(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-7.9640e-04,  3.1442e-03,  1.7340e-03,  ..., -1.3006e-02,\n",
       "         -1.6810e-02, -1.8502e-02],\n",
       "        [-1.5749e-02,  2.9127e-03,  3.7363e-03,  ...,  8.5603e-03,\n",
       "          1.8358e-02,  2.9510e-03],\n",
       "        [-8.7606e-03,  4.1433e-03,  3.2255e-03,  ...,  5.7245e-03,\n",
       "          1.2794e-02,  1.0908e-02],\n",
       "        ...,\n",
       "        [-1.5650e-05,  9.9011e-03, -6.1874e-03,  ...,  1.5196e-02,\n",
       "          1.5222e-02,  5.1083e-03],\n",
       "        [-6.7239e-04,  1.2961e-02,  8.9851e-03,  ...,  4.2858e-03,\n",
       "          6.5064e-03,  5.6875e-03],\n",
       "        [ 8.0813e-03,  5.5816e-04,  7.8110e-04,  ...,  1.3629e-02,\n",
       "         -1.4355e-03, -6.2049e-06]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sample from random normal with standard dev = 0.01\n",
    "model.fc1.weight.data.normal_(std=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forward pass\n",
    "\n",
    "Now that we have a network, let's see what happens when we pass in an image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x648 with 2 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 235,
       "width": 424
      },
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Grab some data \n",
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "# Resize images into a 1D vector, new shape is (batch size, color channels, image pixels) \n",
    "images.resize_(64, 1, 784)\n",
    "# or images.resize_(images.shape[0], 1, 784) to automatically get batch size\n",
    "\n",
    "# Forward pass through the network\n",
    "img_idx = 0\n",
    "ps = model.forward(images[img_idx,:])\n",
    "\n",
    "img = images[img_idx]\n",
    "helper.view_classify(img.view(1, 28, 28), ps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see above, our network has basically no idea what this digit is. It's because we haven't trained it yet, all the weights are random!\n",
    "\n",
    "### Using `nn.Sequential`\n",
    "\n",
    "PyTorch provides a convenient way to build networks like this where a tensor is passed sequentially through operations, `nn.Sequential` ([documentation](https://pytorch.org/docs/master/nn.html#torch.nn.Sequential)). Using this to build the equivalent network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Linear(in_features=784, out_features=128, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=128, out_features=64, bias=True)\n",
      "  (3): ReLU()\n",
      "  (4): Linear(in_features=64, out_features=10, bias=True)\n",
      "  (5): Softmax(dim=1)\n",
      ")\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x648 with 2 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 235,
       "width": 424
      },
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Hyperparameters for our network\n",
    "input_size = 784\n",
    "hidden_sizes = [128, 64]\n",
    "output_size = 10\n",
    "\n",
    "# Build a feed-forward network\n",
    "model = nn.Sequential(nn.Linear(input_size, hidden_sizes[0]),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(hidden_sizes[0], hidden_sizes[1]),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(hidden_sizes[1], output_size),\n",
    "                      nn.Softmax(dim=1))\n",
    "print(model)\n",
    "\n",
    "# Forward pass through the network and display output\n",
    "images, labels = next(iter(trainloader))\n",
    "images.resize_(images.shape[0], 1, 784)\n",
    "ps = model.forward(images[0,:])\n",
    "helper.view_classify(images[0].view(1, 28, 28), ps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The operations are availble by passing in the appropriate index. For example, if you want to get first Linear operation and look at the weights, you'd use `model[0]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear(in_features=784, out_features=128, bias=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-0.0177, -0.0268, -0.0221,  ..., -0.0261, -0.0206,  0.0148],\n",
       "        [-0.0229, -0.0008,  0.0259,  ..., -0.0191, -0.0068,  0.0327],\n",
       "        [ 0.0065,  0.0248,  0.0102,  ...,  0.0257,  0.0177,  0.0343],\n",
       "        ...,\n",
       "        [-0.0223,  0.0015, -0.0160,  ...,  0.0141,  0.0222,  0.0314],\n",
       "        [-0.0066, -0.0139,  0.0106,  ...,  0.0121,  0.0148, -0.0241],\n",
       "        [ 0.0266,  0.0248, -0.0068,  ...,  0.0086, -0.0107,  0.0238]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(model[0])\n",
    "model[0].weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also pass in an `OrderedDict` to name the individual layers and operations, instead of using incremental integers. Note that dictionary keys must be unique, so _each operation must have a different name_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (fc1): Linear(in_features=784, out_features=128, bias=True)\n",
       "  (relu1): ReLU()\n",
       "  (fc2): Linear(in_features=128, out_features=64, bias=True)\n",
       "  (relu2): ReLU()\n",
       "  (output): Linear(in_features=64, out_features=10, bias=True)\n",
       "  (softmax): Softmax(dim=1)\n",
       ")"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import OrderedDict\n",
    "model = nn.Sequential(OrderedDict([\n",
    "                      ('fc1', nn.Linear(input_size, hidden_sizes[0])),\n",
    "                      ('relu1', nn.ReLU()),\n",
    "                      ('fc2', nn.Linear(hidden_sizes[0], hidden_sizes[1])),\n",
    "                      ('relu2', nn.ReLU()),\n",
    "                      ('output', nn.Linear(hidden_sizes[1], output_size)),\n",
    "                      ('softmax', nn.Softmax(dim=1))]))\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you can access layers either by integer or the name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear(in_features=784, out_features=128, bias=True)\n",
      "Linear(in_features=784, out_features=128, bias=True)\n"
     ]
    }
   ],
   "source": [
    "print(model[0])\n",
    "print(model.fc1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next notebook, we'll see how we can train a neural network to accuractly predict the numbers appearing in the MNIST images."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
