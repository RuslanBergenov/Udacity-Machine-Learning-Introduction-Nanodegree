1
00:00:00,090 --> 00:00:02,290
在本课中 我们将重复使用回归和分类

2
00:00:02,290 --> 00:00:06,400
的概念 所以让我们先回顾一下它们的定义

3
00:00:06,400 --> 00:00:11,336
回归模型是一个预测值的模型 例如 4 -3 或 6.7

4
00:00:11,336 --> 00:00:15,910
在左边的图表中 我们绘制了一条紧密拟合数据的直线

5
00:00:15,910 --> 00:00:17,940
如果 x 轴上有一个新值

6
00:00:17,940 --> 00:00:21,750
则可以在直线上找到相应的 y 值来近似它

7
00:00:21,750 --> 00:00:24,980
分类问题主要用来确定状态

8
00:00:24,980 --> 00:00:29,210
例如 正/负 是/否 猫/狗

9
00:00:29,210 --> 00:00:34,020
在右边的图形中 我们有一些蓝色的点 标记为正

10
00:00:34,020 --> 00:00:35,940
以及一些红色的点 标记为负

11
00:00:35,939 --> 00:00:38,359
我们画了一条区分它们的直线

12
00:00:38,359 --> 00:00:40,269
当此平面上有一个新值时

13
00:00:40,270 --> 00:00:44,340
我们根据它属于这两个区域中的哪一个来猜测它的状态

14
00:00:44,340 --> 00:00:47,600
那么总结起来 就是回归返回的是值

15
00:00:47,600 --> 00:00:49,740
而分类返回的是状态

16
00:00:49,740 --> 00:00:53,310
那么 现在你建好了一个模型 你如何向自己

17
00:00:53,310 --> 00:00:55,500
和他人证明这个模型是良好的呢？

18
00:00:55,500 --> 00:00:56,969
方法就是测试

19
00:00:56,969 --> 00:01:00,250
我们来看 BUFF 的图片 它显示了一个简单的回归示例

20
00:01:00,250 --> 00:01:02,640
我们的数据与分数对应

21
00:01:02,640 --> 00:01:05,219
我们训练了两个模型来拟合该数据

22
00:01:05,219 --> 00:01:07,439
一个是直线 另一个是曲线

23
00:01:08,549 --> 00:01:11,920
现在的问题是 这两个模型哪个更好？

24
00:01:11,920 --> 00:01:14,120
右边这个完美拟合了数据

25
00:01:14,120 --> 00:01:16,042
而左边这个没有

26
00:01:16,042 --> 00:01:18,010
我们会忍不住说右边的更好

27
00:01:18,010 --> 00:01:22,350
要确定拟合性能 我们可以取一个新的点 这个红色点

28
00:01:22,349 --> 00:01:26,164
左边的模型对这点近似地较好 而右边的

29
00:01:26,165 --> 00:01:29,410
模型近似的效果较差

30
00:01:29,409 --> 00:01:32,500
所以最终来看 左侧的模型比

31
00:01:32,500 --> 00:01:33,680
右边的模型要好

32
00:01:33,680 --> 00:01:36,630
左侧模型的优点在于尽管它没有

33
00:01:36,629 --> 00:01:40,847
完美拟合数据 但它的泛化能力比右边的好

34
00:01:40,847 --> 00:01:43,480
右边的模型太过于完美拟合数据

35
00:01:43,480 --> 00:01:45,020
结果将这些数据记了下来

36
00:01:45,019 --> 00:01:48,839
这称为过拟合 我们将在后面的纳米学位课程中学习

37
00:01:48,840 --> 00:01:53,109
现在的问题是 我们如何找到一个泛化能力高的模型呢？

38
00:01:53,109 --> 00:01:56,250
在这里 我们就要引入测试的概念

39
00:01:56,250 --> 00:02:01,409
我们要在这里做的 是将数据分为两个集合 一个是训练集

40
00:02:01,409 --> 00:02:03,099
一个测试集

41
00:02:03,099 --> 00:02:07,449
在这个图中 训练集是灰色点的集合

42
00:02:07,450 --> 00:02:09,740
测试集是白色点的集合

43
00:02:09,740 --> 00:02:13,680
接下来 顾名思义 我们要用训练集

44
00:02:13,680 --> 00:02:17,875
来训练模型 然后在测试集中测试结果

45
00:02:17,875 --> 00:02:21,495
现在我们有两个数据集 由灰色点组成的训练集

46
00:02:21,495 --> 00:02:24,314
和用白色点组成的测试集

47
00:02:24,314 --> 00:02:27,974
可以看到训练了训练集的模型 即灰色点

48
00:02:27,974 --> 00:02:31,905
右边的模型看起来似乎比左边的模型好

49
00:02:31,905 --> 00:02:36,396
但是一旦我们在测试集上测试 即白色点 可以看到

50
00:02:36,395 --> 00:02:40,639
左侧的模型更好 因为红色所表示的误差更小

51
00:02:40,639 --> 00:02:43,189
因此可以得出结论 左侧的模型更好

52
00:02:43,189 --> 00:02:46,609
因为虽然它在训练集上的表现略弱

53
00:02:46,610 --> 00:02:48,885
但它在测试集上的效果更好

54
00:02:48,884 --> 00:02:51,894
我们可以将相同的过程用于分类问题 就像这里的

55
00:02:51,895 --> 00:02:52,835
这个

56
00:02:52,835 --> 00:02:56,795
我们训练了两个分类模型来分离蓝正点

57
00:02:56,794 --> 00:02:58,634
和红负点

58
00:02:58,634 --> 00:03:01,974
左边的这个模型还好 因为它仅犯了少数几个错误

59
00:03:01,974 --> 00:03:03,814
右侧的这个非常棒

60
00:03:03,814 --> 00:03:06,344
因为它准确区分了所有的点

61
00:03:06,344 --> 00:03:09,740
但直觉告诉我们左边的可能更好

62
00:03:09,740 --> 00:03:11,320
因为它更泛化

63
00:03:11,319 --> 00:03:15,150
同时 左边的模型将这些异常数值视为噪声

64
00:03:15,150 --> 00:03:19,099
并尝试以更简单和更一般的方式来拟合数据

65
00:03:19,099 --> 00:03:21,710
所以为了挑选一个好的模型 我们需要取一些点

66
00:03:21,710 --> 00:03:23,510
称之为测试集

67
00:03:23,509 --> 00:03:26,919
那么 训练集用实心点表示

68
00:03:26,919 --> 00:03:30,239
测试集用空心点表示

69
00:03:30,240 --> 00:03:32,010
现在我们训练这两个模型

70
00:03:32,009 --> 00:03:35,310
注意这两个点对训练集的拟合都不错

71
00:03:35,310 --> 00:03:39,030
但当我们引入测试集 左边的模型

72
00:03:39,030 --> 00:03:43,879
仅有一处错误 而右边的点有两处错误

73
00:03:43,879 --> 00:03:48,469
因此 通过测试 我们得出结论左边的模型更好

74
00:03:48,469 --> 00:03:51,046
在 sklearn 中这样做的方式很简单 使用

75
00:03:51,046 --> 00:03:54,359
模型选择包中的 train-test-split 函数即可

76
00:03:54,360 --> 00:03:56,816
首先 我们导入 train_test_split

77
00:03:56,816 --> 00:04:00,195
train_test_split 函数将以下作为参数

78
00:04:00,195 --> 00:04:04,280
输入、输出以及

79
00:04:04,280 --> 00:04:07,469
我们想留作测试数据的数据比例

80
00:04:07,469 --> 00:04:11,800
例如 test_size 等于 0.25 指将我们 25% 的数据

81
00:04:11,800 --> 00:04:14,400
用作测试集

82
00:04:14,400 --> 00:04:16,959
在这个例子中 我们有 16 个数据点

83
00:04:16,959 --> 00:04:19,420
所以其中 4 个将用作测试数据

84
00:04:19,420 --> 00:04:22,150
而剩下的 12 个用作训练数据

85
00:04:22,149 --> 00:04:25,459
有一条黄金法则我们永远都不能违背

86
00:04:25,459 --> 00:04:30,579
那就是 不能将测试数据用于训练

87
00:04:30,579 --> 00:04:33,000
这一点非常重要 当我们选择一些数据用于

88
00:04:33,000 --> 00:04:37,771
测试时 必须将它们放在一边 直到最后一步再用

89
00:04:37,771 --> 00:04:41,379
而且我们不能使用它们来训练模型

90
00:04:41,379 --> 00:04:44,719
如果不注意 我们很容易违反它

91
00:04:44,720 --> 00:04:45,640
你很快就会知道是怎么回事

